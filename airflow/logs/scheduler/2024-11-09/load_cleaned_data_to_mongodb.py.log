[2024-11-09T08:22:29.951+0100] {processor.py:186} INFO - Started process (PID=65053) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:22:29.954+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:22:29.962+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:22:29.960+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:22:30.273+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:22:30.672+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:22:30.671+0100] {override.py:1911} INFO - Created Permission View: can delete on DAG:load_cleaned_data_to_mongodb
[2024-11-09T08:22:30.709+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:22:30.707+0100] {override.py:1911} INFO - Created Permission View: can edit on DAG:load_cleaned_data_to_mongodb
[2024-11-09T08:22:30.749+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:22:30.747+0100] {override.py:1911} INFO - Created Permission View: can read on DAG:load_cleaned_data_to_mongodb
[2024-11-09T08:22:30.784+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:22:30.783+0100] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:load_cleaned_data_to_mongodb
[2024-11-09T08:22:30.810+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:22:30.809+0100] {override.py:1911} INFO - Created Permission View: can create on DAG Run:load_cleaned_data_to_mongodb
[2024-11-09T08:22:30.839+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:22:30.837+0100] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:load_cleaned_data_to_mongodb
[2024-11-09T08:22:30.868+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:22:30.867+0100] {override.py:1911} INFO - Created Permission View: can read on DAG Run:load_cleaned_data_to_mongodb
[2024-11-09T08:22:30.870+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:22:30.869+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:22:30.919+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:22:30.917+0100] {dag.py:3262} INFO - Creating ORM DAG for load_cleaned_data_to_mongodb
[2024-11-09T08:22:30.957+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:22:30.956+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:22:31.018+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 1.090 seconds
[2024-11-09T08:24:25.653+0100] {processor.py:186} INFO - Started process (PID=66585) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:24:25.665+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:24:25.677+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:24:25.674+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:24:25.977+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:24:26.030+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:24:26.029+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:24:26.121+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:24:26.121+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:24:26.228+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.600 seconds
[2024-11-09T08:26:13.875+0100] {processor.py:186} INFO - Started process (PID=68115) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:26:13.886+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:26:13.897+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:26:13.894+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:26:14.126+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:26:14.175+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:26:14.174+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:26:14.247+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:26:14.246+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:26:14.314+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.463 seconds
[2024-11-09T08:27:36.352+0100] {processor.py:186} INFO - Started process (PID=69456) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:27:36.356+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:27:36.369+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:27:36.367+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:27:36.676+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:27:36.761+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:27:36.759+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:27:36.862+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:27:36.861+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:27:36.953+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.636 seconds
[2024-11-09T08:28:14.984+0100] {processor.py:186} INFO - Started process (PID=70056) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:28:14.995+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:28:15.007+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:28:15.003+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:28:15.239+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:28:15.289+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:28:15.287+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:28:15.365+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:28:15.364+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:28:15.435+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.476 seconds
[2024-11-09T08:28:27.889+0100] {processor.py:186} INFO - Started process (PID=70313) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:28:27.900+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:28:27.908+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:28:27.906+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:28:28.173+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:28:28.232+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:28:28.231+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:28:28.326+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:28:28.325+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:28:28.426+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.559 seconds
[2024-11-09T08:29:19.614+0100] {processor.py:186} INFO - Started process (PID=71221) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:29:19.624+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:29:19.631+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:29:19.629+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:29:19.845+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:29:19.901+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:29:19.900+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:29:19.988+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:29:19.987+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:29:20.055+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.463 seconds
[2024-11-09T08:29:39.024+0100] {processor.py:186} INFO - Started process (PID=71455) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:29:39.028+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:29:39.037+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:29:39.035+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:29:39.301+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:29:39.351+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:29:39.350+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:29:39.420+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:29:39.420+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:29:39.494+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.493 seconds
[2024-11-09T08:30:11.710+0100] {processor.py:186} INFO - Started process (PID=71903) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:30:11.720+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:30:11.728+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:30:11.727+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:30:11.961+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:30:12.011+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:30:12.010+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:30:12.084+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:30:12.084+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:30:12.149+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.462 seconds
[2024-11-09T08:30:28.895+0100] {processor.py:186} INFO - Started process (PID=72120) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:30:28.905+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:30:28.915+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:30:28.913+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:30:29.163+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:30:29.213+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:30:29.212+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:30:29.295+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:30:29.294+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:30:29.368+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.496 seconds
[2024-11-09T08:31:01.901+0100] {processor.py:186} INFO - Started process (PID=72471) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:31:01.911+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:31:01.919+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:31:01.918+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:31:02.133+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:31:02.192+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:31:02.191+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:31:02.284+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:31:02.282+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:31:02.369+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.491 seconds
[2024-11-09T08:31:20.926+0100] {processor.py:186} INFO - Started process (PID=72723) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:31:20.929+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:31:20.936+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:31:20.935+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:31:21.171+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:31:21.222+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:31:21.220+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:31:21.298+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:31:21.297+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:31:21.370+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.466 seconds
[2024-11-09T08:31:51.876+0100] {processor.py:186} INFO - Started process (PID=73068) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:31:51.887+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:31:51.895+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:31:51.894+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:31:52.124+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:31:52.175+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:31:52.173+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:31:52.254+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:31:52.253+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:31:52.324+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.469 seconds
[2024-11-09T08:32:12.938+0100] {processor.py:186} INFO - Started process (PID=73298) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:32:12.950+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:32:12.957+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:32:12.956+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:32:13.169+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:32:13.214+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:32:13.213+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:32:13.296+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:32:13.295+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:32:13.367+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.451 seconds
[2024-11-09T08:32:40.479+0100] {processor.py:186} INFO - Started process (PID=73620) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:32:40.482+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:32:40.490+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:32:40.489+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:32:40.711+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:32:40.757+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:32:40.756+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:32:40.824+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:32:40.823+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:32:40.887+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.431 seconds
[2024-11-09T08:33:03.137+0100] {processor.py:186} INFO - Started process (PID=73861) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:33:03.148+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:33:03.156+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:33:03.155+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:33:03.388+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:33:03.438+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:33:03.437+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:33:03.515+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:33:03.514+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:33:03.583+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.468 seconds
[2024-11-09T08:33:29.463+0100] {processor.py:186} INFO - Started process (PID=74183) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:33:29.466+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:33:29.473+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:33:29.472+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:33:29.706+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:33:29.750+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:33:29.749+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:33:29.822+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:33:29.821+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:33:29.888+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.448 seconds
[2024-11-09T08:33:51.182+0100] {processor.py:186} INFO - Started process (PID=74420) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:33:51.193+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:33:51.200+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:33:51.199+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:33:51.429+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:33:51.478+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:33:51.477+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:33:51.557+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:33:51.557+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:33:51.620+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.460 seconds
[2024-11-09T08:34:18.271+0100] {processor.py:186} INFO - Started process (PID=74726) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:34:18.275+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:34:18.283+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:34:18.281+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:34:18.498+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:34:18.544+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:34:18.543+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:34:18.611+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:34:18.610+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:34:18.674+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.426 seconds
[2024-11-09T08:34:39.878+0100] {processor.py:186} INFO - Started process (PID=74963) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:34:39.881+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:34:39.889+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:34:39.888+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:34:40.142+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:34:40.203+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:34:40.202+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:34:40.281+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:34:40.280+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:34:40.351+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.496 seconds
[2024-11-09T08:35:05.783+0100] {processor.py:186} INFO - Started process (PID=75246) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:35:05.794+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:35:05.801+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:35:05.800+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:35:06.017+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:35:06.069+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:35:06.067+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:35:06.146+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:35:06.145+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:35:06.220+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.459 seconds
[2024-11-09T08:35:30.350+0100] {processor.py:186} INFO - Started process (PID=75517) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:35:30.353+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:35:30.359+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:35:30.358+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:35:30.563+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:35:30.606+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:35:30.605+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:35:30.674+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:35:30.674+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:35:30.741+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.410 seconds
[2024-11-09T08:35:56.777+0100] {processor.py:186} INFO - Started process (PID=75822) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:35:56.781+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:35:56.787+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:35:56.786+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:35:57.045+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:35:57.119+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:35:57.117+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:35:57.204+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:35:57.203+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:35:57.270+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.514 seconds
[2024-11-09T08:36:19.515+0100] {processor.py:186} INFO - Started process (PID=76273) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:36:19.533+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:36:19.541+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:36:19.539+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:36:19.776+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:36:19.848+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:36:19.847+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:36:19.930+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:36:19.929+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:36:20.032+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.540 seconds
[2024-11-09T08:36:47.050+0100] {processor.py:186} INFO - Started process (PID=76791) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:36:47.053+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:36:47.060+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:36:47.059+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:36:47.296+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:36:47.346+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:36:47.345+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:36:47.424+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:36:47.423+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:36:47.484+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.457 seconds
[2024-11-09T08:37:10.001+0100] {processor.py:186} INFO - Started process (PID=77062) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:37:10.012+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:37:10.019+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:37:10.018+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:37:10.245+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:37:10.295+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:37:10.294+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:37:10.382+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:37:10.381+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:37:10.455+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.474 seconds
[2024-11-09T08:37:39.861+0100] {processor.py:186} INFO - Started process (PID=77479) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:37:39.873+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:37:39.884+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:37:39.882+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:37:40.282+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:37:40.383+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:37:40.380+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:37:40.523+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:37:40.521+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:37:40.621+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.795 seconds
[2024-11-09T08:38:01.074+0100] {processor.py:186} INFO - Started process (PID=77838) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:38:01.085+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:38:01.092+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:38:01.091+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:38:01.337+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:38:01.387+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:38:01.385+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:38:01.480+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:38:01.480+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:38:01.572+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.521 seconds
[2024-11-09T08:38:33.729+0100] {processor.py:186} INFO - Started process (PID=78289) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:38:33.733+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:38:33.742+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:38:33.740+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:38:33.983+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:38:34.033+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:38:34.031+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:38:34.113+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:38:34.112+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:38:34.170+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.464 seconds
[2024-11-09T08:38:52.604+0100] {processor.py:186} INFO - Started process (PID=78522) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:38:52.608+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:38:52.616+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:38:52.614+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:38:52.887+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:38:52.937+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:38:52.936+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:38:53.022+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:38:53.021+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:38:53.095+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.513 seconds
[2024-11-09T08:39:27.252+0100] {processor.py:186} INFO - Started process (PID=78961) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:39:27.262+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:39:27.270+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:39:27.269+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:39:27.506+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:39:27.557+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:39:27.556+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:39:27.636+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:39:27.635+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:39:27.739+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.512 seconds
[2024-11-09T08:39:43.892+0100] {processor.py:186} INFO - Started process (PID=79165) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:39:43.895+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:39:43.903+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:39:43.901+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:39:44.154+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:39:44.202+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:39:44.201+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:39:44.276+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:39:44.275+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:39:44.346+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.477 seconds
[2024-11-09T08:40:16.457+0100] {processor.py:186} INFO - Started process (PID=79541) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:40:16.469+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:40:16.476+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:40:16.475+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:40:16.717+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:40:16.771+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:40:16.769+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:40:16.851+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:40:16.850+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:40:16.925+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.490 seconds
[2024-11-09T08:40:30.390+0100] {processor.py:186} INFO - Started process (PID=79734) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:40:30.393+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:40:30.400+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:40:30.399+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:40:30.630+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:40:30.678+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:40:30.677+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:40:30.756+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:40:30.755+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:40:30.823+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.455 seconds
[2024-11-09T08:41:07.427+0100] {processor.py:186} INFO - Started process (PID=80136) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:41:07.438+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:41:07.446+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:41:07.445+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:41:07.676+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:41:07.729+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:41:07.727+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:41:07.810+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:41:07.809+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:41:07.891+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.487 seconds
[2024-11-09T08:41:15.906+0100] {processor.py:186} INFO - Started process (PID=80270) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:41:15.909+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:41:15.916+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:41:15.915+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:41:16.145+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:41:16.196+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:41:16.195+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:41:16.272+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:41:16.271+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:41:16.344+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.460 seconds
[2024-11-09T08:41:58.164+0100] {processor.py:186} INFO - Started process (PID=80733) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:41:58.174+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:41:58.183+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:41:58.182+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:41:58.421+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:41:58.470+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:41:58.468+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:41:58.547+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:41:58.546+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:41:58.620+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.478 seconds
[2024-11-09T08:42:03.920+0100] {processor.py:186} INFO - Started process (PID=80804) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:42:03.932+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:42:03.939+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:42:03.938+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:42:04.184+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:42:04.235+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:42:04.234+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:42:04.318+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:42:04.317+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:42:04.392+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.495 seconds
[2024-11-09T08:42:50.515+0100] {processor.py:186} INFO - Started process (PID=81323) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:42:50.526+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:42:50.533+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:42:50.532+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:42:50.760+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:42:50.810+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:42:50.809+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:42:50.884+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:42:50.883+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:42:50.951+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.458 seconds
[2024-11-09T08:42:52.358+0100] {processor.py:186} INFO - Started process (PID=81338) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:42:52.361+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:42:52.369+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:42:52.367+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:42:52.588+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:42:52.632+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:42:52.631+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:42:52.704+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:42:52.704+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:42:52.770+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.434 seconds
[2024-11-09T08:43:38.800+0100] {processor.py:186} INFO - Started process (PID=81860) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:43:38.806+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:43:38.813+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:43:38.812+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:43:39.059+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:43:39.109+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:43:39.108+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:43:39.181+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:43:39.180+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:43:39.249+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.473 seconds
[2024-11-09T08:43:39.669+0100] {processor.py:186} INFO - Started process (PID=81882) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:43:39.672+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:43:39.680+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:43:39.679+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:43:39.909+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:43:39.957+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:43:39.955+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:43:40.030+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:43:40.030+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:43:40.106+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.461 seconds
[2024-11-09T08:44:27.718+0100] {processor.py:186} INFO - Started process (PID=82408) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:44:27.721+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:44:27.730+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:44:27.728+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:44:27.976+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:44:28.027+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:44:28.026+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:44:28.099+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:44:28.098+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:44:28.170+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.477 seconds
[2024-11-09T08:44:28.979+0100] {processor.py:186} INFO - Started process (PID=82419) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:44:28.982+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:44:28.989+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:44:28.988+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:44:29.223+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:44:29.277+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:44:29.275+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:44:29.355+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:44:29.355+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:44:29.418+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.461 seconds
[2024-11-09T08:45:15.783+0100] {processor.py:186} INFO - Started process (PID=82933) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:45:15.795+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:45:15.803+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:45:15.801+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:45:16.040+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:45:16.090+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:45:16.089+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:45:16.188+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:45:16.187+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:45:16.257+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.497 seconds
[2024-11-09T08:45:18.401+0100] {processor.py:186} INFO - Started process (PID=82960) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:45:18.404+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:45:18.412+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:45:18.411+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:45:18.640+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:45:18.698+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:45:18.696+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:45:18.792+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:45:18.791+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:45:18.885+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.506 seconds
[2024-11-09T08:46:01.955+0100] {processor.py:186} INFO - Started process (PID=83450) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:46:01.958+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:46:01.966+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:46:01.965+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:46:02.206+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:46:02.256+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:46:02.254+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:46:02.345+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:46:02.344+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:46:02.410+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.477 seconds
[2024-11-09T08:46:10.308+0100] {processor.py:186} INFO - Started process (PID=83542) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:46:10.311+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:46:10.319+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:46:10.317+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:46:10.548+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:46:10.598+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:46:10.596+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:46:10.675+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:46:10.674+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:46:10.746+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.460 seconds
[2024-11-09T08:46:49.286+0100] {processor.py:186} INFO - Started process (PID=84053) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:46:49.289+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:46:49.297+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:46:49.296+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:46:49.518+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:46:49.567+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:46:49.566+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:46:49.643+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:46:49.642+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:46:49.722+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.458 seconds
[2024-11-09T08:46:57.775+0100] {processor.py:186} INFO - Started process (PID=84164) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:46:57.778+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:46:57.785+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:46:57.784+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:46:58.043+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:46:58.097+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:46:58.095+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:46:58.181+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:46:58.180+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:46:58.262+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.511 seconds
[2024-11-09T08:47:39.380+0100] {processor.py:186} INFO - Started process (PID=84646) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:47:39.406+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:47:39.414+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:47:39.413+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:47:39.652+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:47:39.708+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:47:39.707+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:47:39.784+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:47:39.783+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:47:39.884+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.525 seconds
[2024-11-09T08:47:48.078+0100] {processor.py:186} INFO - Started process (PID=84766) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:47:48.081+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:47:48.090+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:47:48.088+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:47:48.331+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:47:48.381+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:47:48.380+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:47:48.470+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:47:48.469+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:47:48.534+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.478 seconds
[2024-11-09T08:48:32.620+0100] {processor.py:186} INFO - Started process (PID=85345) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:48:32.631+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:48:32.639+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:48:32.637+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:48:32.890+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:48:32.940+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:48:32.939+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:48:33.023+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:48:33.022+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:48:33.101+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.503 seconds
[2024-11-09T08:48:41.560+0100] {processor.py:186} INFO - Started process (PID=85442) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:48:41.571+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:48:41.581+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:48:41.579+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:48:41.838+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:48:41.900+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:48:41.899+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:48:41.982+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:48:41.981+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:48:42.057+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.520 seconds
[2024-11-09T08:49:23.171+0100] {processor.py:186} INFO - Started process (PID=85959) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:49:23.183+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:49:23.190+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:49:23.189+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:49:23.465+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:49:23.525+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:49:23.524+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:49:23.624+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:49:23.622+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:49:23.731+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.582 seconds
[2024-11-09T08:49:32.195+0100] {processor.py:186} INFO - Started process (PID=86115) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:49:32.199+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:49:32.209+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:49:32.208+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:49:32.483+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:49:32.549+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:49:32.547+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:49:32.680+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:49:32.679+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:49:32.773+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.604 seconds
[2024-11-09T08:50:12.994+0100] {processor.py:186} INFO - Started process (PID=86609) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:50:13.004+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:50:13.012+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:50:13.011+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:50:13.243+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:50:13.296+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:50:13.295+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:50:13.377+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:50:13.376+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:50:13.453+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.483 seconds
[2024-11-09T08:50:22.185+0100] {processor.py:186} INFO - Started process (PID=86762) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:50:22.188+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:50:22.197+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:50:22.196+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:50:22.467+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:50:22.524+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:50:22.523+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:50:22.615+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:50:22.614+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:50:22.691+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.532 seconds
[2024-11-09T08:51:07.929+0100] {processor.py:186} INFO - Started process (PID=87398) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:51:07.933+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:51:07.942+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:51:07.940+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:51:08.284+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:51:08.357+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:51:08.356+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:51:08.488+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:51:08.486+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:51:08.571+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.668 seconds
[2024-11-09T08:51:17.067+0100] {processor.py:186} INFO - Started process (PID=87523) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:51:17.072+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:51:17.083+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:51:17.081+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:51:17.454+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:51:17.531+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:51:17.529+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:51:17.661+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:51:17.660+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:51:17.767+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.736 seconds
[2024-11-09T08:52:07.948+0100] {processor.py:186} INFO - Started process (PID=88231) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:52:07.954+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:52:07.965+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:52:07.963+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:52:08.325+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:52:08.394+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:52:08.393+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:52:08.513+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:52:08.512+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:52:08.604+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.692 seconds
[2024-11-09T08:52:17.801+0100] {processor.py:186} INFO - Started process (PID=88343) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:52:17.805+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:52:17.812+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:52:17.811+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:52:18.052+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:52:18.098+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:52:18.097+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:52:18.167+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:52:18.166+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:52:18.227+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.446 seconds
[2024-11-09T08:53:04.614+0100] {processor.py:186} INFO - Started process (PID=89077) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:53:04.625+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:53:04.632+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:53:04.631+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:53:04.878+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:53:04.953+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:53:04.951+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:53:05.066+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:53:05.065+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:53:05.176+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.583 seconds
[2024-11-09T08:53:13.957+0100] {processor.py:186} INFO - Started process (PID=89199) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:53:13.962+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:53:13.969+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:53:13.968+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:53:14.204+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:53:14.256+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:53:14.255+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:53:14.331+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:53:14.330+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:53:14.428+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.492 seconds
[2024-11-09T08:53:58.230+0100] {processor.py:186} INFO - Started process (PID=89772) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:53:58.253+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:53:58.262+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:53:58.260+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:53:58.546+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:53:58.603+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:53:58.602+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:53:58.699+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:53:58.698+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:53:58.832+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.628 seconds
[2024-11-09T08:54:10.817+0100] {processor.py:186} INFO - Started process (PID=89911) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:54:10.830+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:54:10.838+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:54:10.837+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:54:11.146+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:54:11.211+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:54:11.210+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:54:11.318+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:54:11.317+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:54:11.426+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.636 seconds
[2024-11-09T08:55:01.701+0100] {processor.py:186} INFO - Started process (PID=90574) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:55:01.704+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:55:01.712+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:55:01.710+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:55:01.961+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:55:02.042+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:55:02.040+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:55:02.120+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:55:02.119+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:55:02.197+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.518 seconds
[2024-11-09T08:55:18.835+0100] {processor.py:186} INFO - Started process (PID=90797) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:55:18.839+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:55:18.846+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:55:18.845+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:55:19.076+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:55:19.130+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:55:19.129+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:55:19.207+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:55:19.206+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:55:19.269+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.456 seconds
[2024-11-09T08:56:20.363+0100] {processor.py:186} INFO - Started process (PID=91563) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:56:20.375+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:56:20.382+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:56:20.381+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:56:20.643+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:56:20.696+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:56:20.695+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:56:20.775+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:56:20.774+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:56:20.843+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.502 seconds
[2024-11-09T08:57:17.035+0100] {processor.py:186} INFO - Started process (PID=92282) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:57:17.046+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:57:17.053+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:57:17.052+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:57:17.282+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:57:17.335+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:57:17.333+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:57:17.412+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:57:17.411+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:57:17.482+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.469 seconds
[2024-11-09T08:58:05.573+0100] {processor.py:186} INFO - Started process (PID=92925) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:58:05.576+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:58:05.583+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:58:05.582+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:58:05.815+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:58:05.866+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:58:05.864+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:58:05.960+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:58:05.959+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:58:06.038+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.488 seconds
[2024-11-09T08:59:00.578+0100] {processor.py:186} INFO - Started process (PID=93653) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:59:00.589+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:59:00.597+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:59:00.595+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:59:00.823+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:59:00.876+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:59:00.874+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:59:00.951+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:59:00.951+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:59:01.026+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.470 seconds
[2024-11-09T08:59:51.404+0100] {processor.py:186} INFO - Started process (PID=94292) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:59:51.416+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T08:59:51.423+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:59:51.422+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:59:51.651+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T08:59:51.701+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:59:51.699+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T08:59:51.780+0100] {logging_mixin.py:190} INFO - [2024-11-09T08:59:51.779+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T08:59:51.858+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.477 seconds
[2024-11-09T09:00:42.716+0100] {processor.py:186} INFO - Started process (PID=94976) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:00:42.727+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:00:42.734+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:00:42.733+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:00:42.958+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:00:43.006+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:00:43.005+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:00:43.084+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:00:43.083+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:00:43.153+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.458 seconds
[2024-11-09T09:01:34.875+0100] {processor.py:186} INFO - Started process (PID=95520) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:01:34.878+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:01:34.886+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:01:34.884+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:01:35.120+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:01:35.169+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:01:35.168+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:01:35.244+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:01:35.244+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:01:35.329+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.480 seconds
[2024-11-09T09:02:28.513+0100] {processor.py:186} INFO - Started process (PID=96168) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:02:28.525+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:02:28.534+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:02:28.533+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:02:28.855+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:02:28.922+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:02:28.921+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:02:29.014+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:02:29.014+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:02:29.087+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.600 seconds
[2024-11-09T09:03:23.467+0100] {processor.py:186} INFO - Started process (PID=96827) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:03:23.479+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:03:23.488+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:03:23.487+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:03:23.827+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:03:23.894+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:03:23.893+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:03:23.990+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:03:23.989+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:03:24.080+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.641 seconds
[2024-11-09T09:04:19.169+0100] {processor.py:186} INFO - Started process (PID=97580) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:04:19.192+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:04:19.200+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:04:19.199+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:04:19.443+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:04:19.500+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:04:19.499+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:04:19.593+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:04:19.592+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:04:19.713+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.571 seconds
[2024-11-09T09:05:18.448+0100] {processor.py:186} INFO - Started process (PID=98334) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:05:18.459+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:05:18.470+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:05:18.469+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:05:18.747+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:05:18.822+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:05:18.820+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:05:18.905+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:05:18.904+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:05:18.991+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.567 seconds
[2024-11-09T09:06:06.889+0100] {processor.py:186} INFO - Started process (PID=99035) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:06:06.893+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:06:06.904+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:06:06.902+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:06:07.248+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:06:07.304+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:06:07.303+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:06:07.397+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:06:07.396+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:06:07.485+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.657 seconds
[2024-11-09T09:06:56.092+0100] {processor.py:186} INFO - Started process (PID=99729) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:06:56.095+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:06:56.103+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:06:56.102+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:06:56.348+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:06:56.404+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:06:56.402+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:06:56.494+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:06:56.493+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:06:56.566+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.515 seconds
[2024-11-09T09:07:47.782+0100] {processor.py:186} INFO - Started process (PID=100409) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:07:47.785+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:07:47.792+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:07:47.791+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:07:47.999+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:07:48.044+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:07:48.043+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:07:48.115+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:07:48.114+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:07:48.176+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.429 seconds
[2024-11-09T09:08:37.235+0100] {processor.py:186} INFO - Started process (PID=101129) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:08:37.238+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:08:37.246+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:08:37.245+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:08:37.484+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:08:37.537+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:08:37.536+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:08:37.620+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:08:37.619+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:08:37.691+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.494 seconds
[2024-11-09T09:09:29.160+0100] {processor.py:186} INFO - Started process (PID=101836) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:09:29.170+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:09:29.179+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:09:29.177+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:09:29.421+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:09:29.473+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:09:29.471+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:09:29.565+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:09:29.564+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:09:29.643+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.522 seconds
[2024-11-09T09:10:20.873+0100] {processor.py:186} INFO - Started process (PID=102381) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:10:20.884+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:10:20.891+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:10:20.890+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:10:21.116+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:10:21.164+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:10:21.163+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:10:21.238+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:10:21.238+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:10:21.309+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.474 seconds
[2024-11-09T09:11:13.584+0100] {processor.py:186} INFO - Started process (PID=102932) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:11:13.588+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:11:13.595+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:11:13.594+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:11:13.845+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:11:13.894+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:11:13.893+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:11:13.975+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:11:13.974+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:11:14.047+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.500 seconds
[2024-11-09T09:12:09.199+0100] {processor.py:186} INFO - Started process (PID=103698) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:12:09.210+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:12:09.221+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:12:09.219+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:12:09.518+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:12:09.580+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:12:09.578+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:12:09.720+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:12:09.719+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:12:09.813+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.665 seconds
[2024-11-09T09:13:03.701+0100] {processor.py:186} INFO - Started process (PID=104351) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:13:03.713+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:13:03.723+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:13:03.721+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:13:04.031+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:13:04.089+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:13:04.088+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:13:04.165+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:13:04.164+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:13:04.220+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.575 seconds
[2024-11-09T09:13:55.502+0100] {processor.py:186} INFO - Started process (PID=105057) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:13:55.513+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:13:55.521+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:13:55.520+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:13:55.751+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:13:55.798+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:13:55.797+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:13:55.871+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:13:55.870+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:13:55.933+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.477 seconds
[2024-11-09T09:14:47.159+0100] {processor.py:186} INFO - Started process (PID=105695) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:14:47.170+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:14:47.177+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:14:47.176+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:14:47.407+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:14:47.456+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:14:47.455+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:14:47.538+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:14:47.538+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:14:47.612+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.493 seconds
[2024-11-09T09:15:38.101+0100] {processor.py:186} INFO - Started process (PID=106382) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:15:38.111+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:15:38.118+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:15:38.117+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:15:38.333+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:15:38.380+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:15:38.379+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:15:38.448+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:15:38.448+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:15:38.513+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.447 seconds
[2024-11-09T09:16:31.094+0100] {processor.py:186} INFO - Started process (PID=107032) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:16:31.105+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:16:31.113+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:16:31.112+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:16:31.356+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:16:31.409+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:16:31.408+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:16:31.498+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:16:31.497+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:16:31.589+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.535 seconds
[2024-11-09T09:17:23.218+0100] {processor.py:186} INFO - Started process (PID=107620) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:17:23.222+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:17:23.231+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:17:23.229+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:17:23.446+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:17:23.491+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:17:23.490+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:17:23.563+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:17:23.563+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:17:23.629+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.462 seconds
[2024-11-09T09:18:14.112+0100] {processor.py:186} INFO - Started process (PID=108343) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:18:14.117+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:18:14.128+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:18:14.126+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:18:14.373+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:18:14.429+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:18:14.427+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:18:14.504+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:18:14.503+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:18:14.577+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.524 seconds
[2024-11-09T09:19:04.403+0100] {processor.py:186} INFO - Started process (PID=108930) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:19:04.414+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:19:04.422+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:19:04.421+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:19:04.701+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:19:04.764+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:19:04.763+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:19:04.842+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:19:04.842+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:19:04.922+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.579 seconds
[2024-11-09T09:19:56.571+0100] {processor.py:186} INFO - Started process (PID=109539) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:19:56.582+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:19:56.590+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:19:56.589+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:19:56.838+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:19:56.887+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:19:56.886+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:19:56.962+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:19:56.961+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:19:57.035+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.502 seconds
[2024-11-09T09:20:47.032+0100] {processor.py:186} INFO - Started process (PID=110244) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:20:47.044+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:20:47.053+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:20:47.052+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:20:47.315+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:20:47.367+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:20:47.365+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:20:47.449+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:20:47.448+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:20:47.521+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.539 seconds
[2024-11-09T09:21:39.614+0100] {processor.py:186} INFO - Started process (PID=110861) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:21:39.618+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:21:39.625+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:21:39.624+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:21:39.856+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:21:39.905+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:21:39.904+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:21:39.984+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:21:39.983+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:21:40.049+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.476 seconds
[2024-11-09T09:22:33.477+0100] {processor.py:186} INFO - Started process (PID=111641) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:22:33.480+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:22:33.488+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:22:33.487+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:22:33.730+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:22:33.780+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:22:33.779+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:22:33.862+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:22:33.861+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:22:33.934+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.496 seconds
[2024-11-09T09:23:28.033+0100] {processor.py:186} INFO - Started process (PID=112296) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:23:28.044+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:23:28.052+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:23:28.050+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:23:28.286+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:23:28.329+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:23:28.328+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:23:28.398+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:23:28.397+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:23:28.477+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.482 seconds
[2024-11-09T09:24:22.107+0100] {processor.py:186} INFO - Started process (PID=112882) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:24:22.111+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:24:22.123+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:24:22.121+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:24:22.410+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:24:22.470+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:24:22.468+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:24:22.565+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:24:22.564+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:24:22.635+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.569 seconds
[2024-11-09T09:25:16.367+0100] {processor.py:186} INFO - Started process (PID=113471) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:25:16.378+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:25:16.386+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:25:16.385+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:25:16.615+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:25:16.664+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:25:16.663+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:25:16.739+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:25:16.739+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:25:16.813+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.487 seconds
[2024-11-09T09:26:09.071+0100] {processor.py:186} INFO - Started process (PID=114063) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:26:09.082+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:26:09.091+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:26:09.090+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:26:09.366+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:26:09.418+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:26:09.417+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:26:09.503+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:26:09.503+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:26:09.577+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.562 seconds
[2024-11-09T09:27:00.841+0100] {processor.py:186} INFO - Started process (PID=114662) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:27:00.853+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:27:00.863+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:27:00.862+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:27:01.227+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:27:01.289+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:27:01.288+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:27:01.402+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:27:01.400+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:27:01.494+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.699 seconds
[2024-11-09T09:27:55.346+0100] {processor.py:186} INFO - Started process (PID=115407) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:27:55.356+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:27:55.364+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:27:55.362+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:27:55.609+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:27:55.659+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:27:55.657+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:27:55.751+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:27:55.750+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:27:55.821+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.520 seconds
[2024-11-09T09:28:50.240+0100] {processor.py:186} INFO - Started process (PID=116030) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:28:50.252+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:28:50.259+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:28:50.258+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:28:50.503+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:28:50.559+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:28:50.557+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:28:50.657+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:28:50.656+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:28:50.730+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.527 seconds
[2024-11-09T09:29:44.684+0100] {processor.py:186} INFO - Started process (PID=116687) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:29:44.695+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:29:44.702+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:29:44.701+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:29:44.935+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:29:44.984+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:29:44.983+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:29:45.067+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:29:45.066+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:29:45.138+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.496 seconds
[2024-11-09T09:30:38.995+0100] {processor.py:186} INFO - Started process (PID=117330) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:30:39.006+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:30:39.014+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:30:39.013+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:30:39.296+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:30:39.362+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:30:39.360+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:30:39.441+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:30:39.440+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:30:39.515+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.560 seconds
[2024-11-09T09:31:34.378+0100] {processor.py:186} INFO - Started process (PID=117987) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:31:34.389+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:31:34.397+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:31:34.396+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:31:34.633+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:31:34.684+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:31:34.683+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:31:34.761+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:31:34.760+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:31:35.205+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.865 seconds
[2024-11-09T09:32:29.415+0100] {processor.py:186} INFO - Started process (PID=118609) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:32:29.426+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:32:29.435+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:32:29.433+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:32:29.698+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:32:29.767+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:32:29.766+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:32:29.861+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:32:29.861+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:32:29.935+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.573 seconds
[2024-11-09T09:33:23.970+0100] {processor.py:186} INFO - Started process (PID=119239) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:33:23.981+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:33:23.989+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:33:23.988+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:33:24.207+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:33:24.251+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:33:24.250+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:33:24.316+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:33:24.315+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:33:24.759+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.829 seconds
[2024-11-09T09:34:17.533+0100] {processor.py:186} INFO - Started process (PID=119870) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:34:17.536+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:34:17.544+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:34:17.542+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:34:17.771+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:34:17.827+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:34:17.826+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:34:17.905+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:34:17.905+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:34:17.981+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.485 seconds
[2024-11-09T09:35:10.614+0100] {processor.py:186} INFO - Started process (PID=120573) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:35:10.625+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:35:10.633+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:35:10.631+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:35:10.885+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:35:10.939+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:35:10.938+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:35:11.018+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:35:11.017+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:35:11.096+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.522 seconds
[2024-11-09T09:36:03.734+0100] {processor.py:186} INFO - Started process (PID=121177) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:36:03.745+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:36:03.753+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:36:03.752+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:36:04.012+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:36:04.064+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:36:04.063+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:36:04.149+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:36:04.148+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:36:04.224+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.538 seconds
[2024-11-09T09:36:56.450+0100] {processor.py:186} INFO - Started process (PID=121766) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:36:56.460+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:36:56.469+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:36:56.467+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:36:56.740+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:36:56.794+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:36:56.793+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:36:56.876+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:36:56.875+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:36:56.961+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.556 seconds
[2024-11-09T09:37:51.733+0100] {processor.py:186} INFO - Started process (PID=122516) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:37:51.743+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:37:51.752+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:37:51.751+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:37:51.983+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:37:52.034+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:37:52.033+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:37:52.529+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:37:52.528+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:37:52.596+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.902 seconds
[2024-11-09T09:38:47.061+0100] {processor.py:186} INFO - Started process (PID=123205) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:38:47.072+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:38:47.079+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:38:47.078+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:38:47.326+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:38:47.383+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:38:47.382+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:38:47.466+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:38:47.466+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:38:47.538+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.516 seconds
[2024-11-09T09:39:41.654+0100] {processor.py:186} INFO - Started process (PID=123893) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:39:41.665+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:39:41.673+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:39:41.671+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:39:41.910+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:39:41.960+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:39:41.959+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:39:42.426+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:39:42.425+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:39:42.507+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.890 seconds
[2024-11-09T09:40:37.738+0100] {processor.py:186} INFO - Started process (PID=124514) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:40:37.749+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:40:37.757+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:40:37.755+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:40:37.972+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:40:38.030+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:40:38.029+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:40:38.114+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:40:38.113+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:40:38.189+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.491 seconds
[2024-11-09T09:41:31.992+0100] {processor.py:186} INFO - Started process (PID=125103) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:41:32.003+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:41:32.011+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:41:32.009+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:41:32.239+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:41:32.287+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:41:32.286+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:41:32.732+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:41:32.731+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:41:32.791+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.836 seconds
[2024-11-09T09:42:27.844+0100] {processor.py:186} INFO - Started process (PID=125884) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:42:27.857+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:42:27.868+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:42:27.866+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:42:28.183+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:42:28.240+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:42:28.239+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:42:28.326+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:42:28.325+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:42:28.404+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.626 seconds
[2024-11-09T09:43:21.156+0100] {processor.py:186} INFO - Started process (PID=126526) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:43:21.167+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:43:21.175+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:43:21.173+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:43:21.407+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:43:21.459+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:43:21.458+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:43:21.874+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:43:21.873+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:43:21.945+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.827 seconds
[2024-11-09T09:44:12.845+0100] {processor.py:186} INFO - Started process (PID=127309) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:44:12.856+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:44:12.864+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:44:12.863+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:44:13.092+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:44:13.535+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:44:13.534+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:44:13.606+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:44:13.605+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:44:13.672+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.866 seconds
[2024-11-09T09:45:07.646+0100] {processor.py:186} INFO - Started process (PID=127949) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:45:07.649+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:45:07.657+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:45:07.655+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:45:07.893+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:45:07.957+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:45:07.955+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:45:08.460+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:45:08.459+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:45:08.521+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.914 seconds
[2024-11-09T09:46:03.382+0100] {processor.py:186} INFO - Started process (PID=128635) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:46:03.393+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:46:03.400+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:46:03.399+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:46:03.603+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:46:04.064+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:46:04.062+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:46:04.143+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:46:04.142+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:46:04.223+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.886 seconds
[2024-11-09T09:46:58.329+0100] {processor.py:186} INFO - Started process (PID=129416) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:46:58.333+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:46:58.341+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:46:58.340+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:46:58.601+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:46:58.655+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:46:58.654+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:46:58.759+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:46:58.758+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:46:59.266+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.983 seconds
[2024-11-09T09:47:56.322+0100] {processor.py:186} INFO - Started process (PID=130262) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:47:56.333+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:47:56.341+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:47:56.339+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:47:56.635+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:47:56.702+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:47:56.700+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:47:57.171+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:47:57.170+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:47:57.250+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.966 seconds
[2024-11-09T09:48:53.764+0100] {processor.py:186} INFO - Started process (PID=130931) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:48:53.774+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:48:53.783+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:48:53.782+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:48:54.017+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:48:54.074+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:48:54.072+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:48:54.176+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:48:54.175+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:48:54.642+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.939 seconds
[2024-11-09T09:49:47.634+0100] {processor.py:186} INFO - Started process (PID=131556) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:49:47.645+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:49:47.653+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:49:47.652+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:49:47.901+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:49:47.953+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:49:47.951+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:49:48.426+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:49:48.426+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:49:48.493+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.901 seconds
[2024-11-09T09:50:40.165+0100] {processor.py:186} INFO - Started process (PID=132306) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:50:40.176+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:50:40.185+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:50:40.183+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:50:40.916+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:50:40.966+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:50:40.964+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:50:41.051+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:50:41.050+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:50:41.131+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 1.011 seconds
[2024-11-09T09:51:31.882+0100] {processor.py:186} INFO - Started process (PID=132962) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:51:31.893+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:51:31.900+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:51:31.899+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:51:32.132+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:51:32.180+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:51:32.179+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:51:32.629+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:51:32.628+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:51:32.714+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.869 seconds
[2024-11-09T09:52:27.846+0100] {processor.py:186} INFO - Started process (PID=133715) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:52:27.857+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:52:27.864+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:52:27.863+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:52:28.487+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:52:28.523+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:52:28.522+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:52:28.590+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:52:28.589+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:52:28.659+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.850 seconds
[2024-11-09T09:53:21.922+0100] {processor.py:186} INFO - Started process (PID=134371) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:53:21.934+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:53:21.945+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:53:21.943+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:53:22.735+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:53:22.792+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:53:22.790+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:53:22.894+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:53:22.893+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:53:22.976+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 1.115 seconds
[2024-11-09T09:54:26.442+0100] {processor.py:186} INFO - Started process (PID=135224) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:54:26.452+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:54:26.460+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:54:26.459+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:54:27.110+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:54:27.148+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:54:27.147+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:54:27.218+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:54:27.217+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:54:27.285+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.882 seconds
[2024-11-09T09:55:22.213+0100] {processor.py:186} INFO - Started process (PID=135854) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:55:22.224+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:55:22.233+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:55:22.231+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:55:22.864+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:55:22.901+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:55:22.900+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:55:22.978+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:55:22.977+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:55:23.048+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.874 seconds
[2024-11-09T09:56:26.201+0100] {processor.py:186} INFO - Started process (PID=136529) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:56:26.204+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:56:26.212+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:56:26.211+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:56:26.839+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:56:26.876+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:56:26.875+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:56:26.945+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:56:26.945+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:56:27.011+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.848 seconds
[2024-11-09T09:57:24.137+0100] {processor.py:186} INFO - Started process (PID=137379) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:57:24.141+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:57:24.149+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:57:24.148+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:57:24.806+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:57:24.844+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:57:24.841+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:57:24.928+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:57:24.927+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:57:24.995+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.904 seconds
[2024-11-09T09:58:29.520+0100] {processor.py:186} INFO - Started process (PID=138421) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:58:29.532+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:58:29.540+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:58:29.538+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:58:30.205+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:58:30.250+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:58:30.249+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:58:30.329+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:58:30.328+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:58:30.406+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.924 seconds
[2024-11-09T09:59:27.936+0100] {processor.py:186} INFO - Started process (PID=139065) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:59:27.946+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T09:59:27.954+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:59:27.953+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:59:28.559+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T09:59:28.595+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:59:28.594+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T09:59:28.667+0100] {logging_mixin.py:190} INFO - [2024-11-09T09:59:28.666+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T09:59:28.729+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.831 seconds
[2024-11-09T10:00:33.510+0100] {processor.py:186} INFO - Started process (PID=139779) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T10:00:33.521+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T10:00:33.529+0100] {logging_mixin.py:190} INFO - [2024-11-09T10:00:33.528+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T10:00:34.192+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T10:00:34.240+0100] {logging_mixin.py:190} INFO - [2024-11-09T10:00:34.238+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T10:00:34.314+0100] {logging_mixin.py:190} INFO - [2024-11-09T10:00:34.313+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T10:00:34.381+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.912 seconds
[2024-11-09T10:01:39.286+0100] {processor.py:186} INFO - Started process (PID=140484) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T10:01:39.296+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T10:01:39.304+0100] {logging_mixin.py:190} INFO - [2024-11-09T10:01:39.303+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T10:01:39.961+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T10:01:39.995+0100] {logging_mixin.py:190} INFO - [2024-11-09T10:01:39.994+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T10:01:40.067+0100] {logging_mixin.py:190} INFO - [2024-11-09T10:01:40.066+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T10:01:40.138+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.895 seconds
[2024-11-09T10:02:50.914+0100] {processor.py:186} INFO - Started process (PID=141258) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T10:02:50.926+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T10:02:50.935+0100] {logging_mixin.py:190} INFO - [2024-11-09T10:02:50.933+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T10:02:51.564+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T10:02:51.616+0100] {logging_mixin.py:190} INFO - [2024-11-09T10:02:51.614+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T10:02:51.706+0100] {logging_mixin.py:190} INFO - [2024-11-09T10:02:51.705+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T10:02:51.788+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.911 seconds
[2024-11-09T10:03:57.229+0100] {processor.py:186} INFO - Started process (PID=142255) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T10:03:57.241+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T10:03:57.251+0100] {logging_mixin.py:190} INFO - [2024-11-09T10:03:57.250+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T10:03:58.021+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T10:03:58.066+0100] {logging_mixin.py:190} INFO - [2024-11-09T10:03:58.064+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T10:03:58.142+0100] {logging_mixin.py:190} INFO - [2024-11-09T10:03:58.141+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T10:03:58.221+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 1.052 seconds
[2024-11-09T10:05:06.175+0100] {processor.py:186} INFO - Started process (PID=143124) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T10:05:06.186+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T10:05:06.194+0100] {logging_mixin.py:190} INFO - [2024-11-09T10:05:06.193+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T10:05:06.807+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T10:05:06.857+0100] {logging_mixin.py:190} INFO - [2024-11-09T10:05:06.855+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T10:05:06.940+0100] {logging_mixin.py:190} INFO - [2024-11-09T10:05:06.939+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T10:05:07.014+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.876 seconds
[2024-11-09T10:06:09.824+0100] {processor.py:186} INFO - Started process (PID=143896) to work on /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T10:06:09.835+0100] {processor.py:914} INFO - Processing file /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py for tasks to queue
[2024-11-09T10:06:09.842+0100] {logging_mixin.py:190} INFO - [2024-11-09T10:06:09.841+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T10:06:10.446+0100] {processor.py:925} INFO - DAG(s) 'load_cleaned_data_to_mongodb' retrieved from /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py
[2024-11-09T10:06:10.480+0100] {logging_mixin.py:190} INFO - [2024-11-09T10:06:10.479+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-09T10:06:10.540+0100] {logging_mixin.py:190} INFO - [2024-11-09T10:06:10.539+0100] {dag.py:4180} INFO - Setting next_dagrun for load_cleaned_data_to_mongodb to 2024-11-08 00:00:00+00:00, run_after=2024-11-09 00:00:00+00:00
[2024-11-09T10:06:10.599+0100] {processor.py:208} INFO - Processing /home/hajar/big_data_airflow_prjt/airflow/dags/load_cleaned_data_to_mongodb.py took 0.818 seconds
